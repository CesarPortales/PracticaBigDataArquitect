{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ejemplos Scrapy César Portales Alonso",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CesarPortales/PracticaBigDataArquitect/blob/master/Ejemplos_Scrapy_C%C3%A9sar_Portales_Alonso.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF10oReQhBf_",
        "colab_type": "text"
      },
      "source": [
        "# **Ejemplos scrapy y uso de API's**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgkqZ7GnrmOQ",
        "colab_type": "text"
      },
      "source": [
        "# **Uso de Google API**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leT2E1YormWk",
        "colab_type": "text"
      },
      "source": [
        "Usaremos Google Api para encontrar las direcciones que se corresponden con las localizaciones y para cálculos de distancias con diversos puntos (en el ejemplo con el Museo del Prado).\n",
        "\n",
        "En teoría habría que hacer una función que pasase las coordenadas como parámetro, no lo he hecho por el coste que supondría. \n",
        "\n",
        "Simplemente pongo un ejemplo de como  acceder a la información "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLjw9fro56TV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "4cee4418-3dd2-4890-a7af-00c2fa6b11bd"
      },
      "source": [
        "pip install requests"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (2.21.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests) (2019.6.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests) (2.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s56lON1rnR1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "f96c724f-aeec-43e9-e41f-02f4a6cd49da"
      },
      "source": [
        "import json, requests\n",
        "\n",
        "\n",
        "url='https://maps.googleapis.com/maps/api/distancematrix/json?units=metric&origins=40.4069528,-3.6708945&destinations=40.4101197,-3.6858859&mode=walking&key=AIzaSyCJ6JxlZGrXzA64nVv-3eYC5rMR7oasgQY'\n",
        "\n",
        "resp = requests.get(url=url)\n",
        "print (resp)\n",
        "data = json.loads(resp.text)\n",
        "print(data)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Response [200]>\n",
            "{'destination_addresses': ['Paseo Fernán Núñez, 6, 28009 Madrid, Spain'], 'origin_addresses': ['Av.mediterraneo-pza.conde Casal, 28009 Madrid, Spain'], 'rows': [{'elements': [{'distance': {'text': '1.5 km', 'value': 1517}, 'duration': {'text': '21 mins', 'value': 1244}, 'status': 'OK'}]}], 'status': 'OK'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8C4PXTThT9d",
        "colab_type": "text"
      },
      "source": [
        "# **Buscamos cual es la última cotización euro-dólar para añadir información del cambio**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvaNOBHihUJy",
        "colab_type": "text"
      },
      "source": [
        "**Instalamos beautifulsoup4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlcuNJR0hVQ7",
        "colab_type": "code",
        "outputId": "2c7006ab-1c9e-4d5c-d3fc-626eee03e320",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install beautifulsoup4"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (4.6.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDehrvuuh6rq",
        "colab_type": "text"
      },
      "source": [
        "**Instalamos requests**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2knuKAkMV_oI",
        "colab_type": "code",
        "outputId": "b470383d-2b32-4150-fdd0-1b2cd54853e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "pip install requests"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (2.21.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests) (2019.6.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6HDaeJLiFZz",
        "colab_type": "text"
      },
      "source": [
        "**Código que obtendría la última cotización de 'Expansión'**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mxrc-Co-cWfc",
        "colab_type": "code",
        "outputId": "c3037917-1a91-4cfb-8e31-e1783c96ce61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "# indicar la ruta\n",
        "url_page='https://www.expansion.com/mercados/cotizaciones/valores/eurodolar_DVEUDU.html'\n",
        "\n",
        "#hacemos el get a la url\n",
        "req = requests.get(url_page)\n",
        "status_code = req.status_code\n",
        "\n",
        "if status_code == 200:\n",
        "\n",
        "    # Pasamos el contenido HTML de la web a un objeto BeautifulSoup()\n",
        "    html = BeautifulSoup(req.text, \"html.parser\")\n",
        "   \n",
        "    # Obtenemos todos los divs donde están las entradas\n",
        "    entradas = html.find_all('div', {'id': 'ultimos_datos'})\n",
        "    \n",
        "    # Recorremos todas las entradas para extraer el valor\n",
        "    for i, entrada in enumerate(entradas):\n",
        "        \n",
        "        # Con el método \"getText()\" no nos devuelve el HTML\n",
        "        titulo = entrada.find('li', {'class': 'cotizacion'}).getText()\n",
        "        \n",
        "       \n",
        "        # Imprimo el valor de la cotización\n",
        "        print (titulo)\n",
        "else:\n",
        "    print(status_code) \n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1,11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvVj2SmwjJXL",
        "colab_type": "text"
      },
      "source": [
        "**--------------------------------------------------------------------------**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOW08NTnjJlh",
        "colab_type": "text"
      },
      "source": [
        "# **Hacemos scrapy para descargar en un csv datos de actividades que realizar en Madrid**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMFaJ9IijJ8C",
        "colab_type": "text"
      },
      "source": [
        "**Montamos nuestra unidad de drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jDjZOY_TGtS",
        "colab_type": "code",
        "outputId": "8b801bbe-3744-4b25-d5d0-81e163ad1b29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eQgmEdcla3I",
        "colab_type": "text"
      },
      "source": [
        "**Generamos ActividadesMadrid.csv en la carpeta BigDataArq/Input**\n",
        "(habría que generar un archivo por cada una de las ciudades con las que se desee trabajar.\n",
        "Simplemente, habrá que cambiar la URL y el nombre del archivo)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeUEwwEiWlEw",
        "colab_type": "code",
        "outputId": "2d3e1f34-e914-40ae-98a7-6adc00fb116e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "# indicar la ruta\n",
        "url_page='https://www.minube.com/a/externalact/c/1252/activity_category'\n",
        "print(url_page)\n",
        "req = requests.get(url_page)\n",
        "status_code = req.status_code\n",
        " \n",
        "filep = open('/content/drive/My Drive/BigDataArq/Input/ActivMad.csv', 'w')\n",
        "if status_code == 200:\n",
        "\n",
        "  # Pasamos el contenido HTML de la web a un objeto BeautifulSoup()\n",
        "  html = BeautifulSoup(req.text, \"html.parser\")\n",
        "  \n",
        "  # Obtenemos todos los divs donde están las entradas\n",
        "  entradas = html.find_all('div', {'class': 'river detail '})\n",
        "  \n",
        " #Por sencillez del código, usaremos dos listas para guardar titulos y precio de las actividades\n",
        "  titulo=[]\n",
        "  precio=[]\n",
        "  \n",
        "  # Recorremos todas las entradas para extraer el título y el precio\n",
        "  for i, entrada in enumerate(entradas):\n",
        "      \n",
        "      visitas=entrada.find_all('a', {'class': 'titleItem'})\n",
        "     \n",
        "      importes=entrada.find_all('div', {'class': 'amount'})  \n",
        "      \n",
        "      \n",
        "      for j, visita in enumerate(visitas):\n",
        "\n",
        "          # Con el método \"getText()\" no nos devuelve el HTML\n",
        "\n",
        "          titulo.append(visita.getText().replace('\\n', '').replace(',', ''))\n",
        "\n",
        "         \n",
        "      \n",
        "      for j,importe in enumerate(importes):\n",
        "        precio.append(importe.getText().replace(',', '.'))\n",
        "      \n",
        "  longitud=len(titulo) \n",
        "  \n",
        "  #Escribimos los rótulos del fichero\n",
        "  filep.write('Título actividad' + ',' + 'Precio' + '\\n')\n",
        "  \n",
        "  for  k in range(1,longitud):\n",
        "    tit=titulo[k]\n",
        "    prec=str(precio[k])\n",
        "                                 \n",
        "    filep.write(tit + ',' + prec + '\\n')\n",
        "\n",
        "else:\n",
        "    print(status_code) \n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://www.minube.com/a/externalact/c/1252/activity_category\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}