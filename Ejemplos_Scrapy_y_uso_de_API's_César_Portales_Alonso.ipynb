{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ejemplos Scrapy y uso de API's César Portales Alonso",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CesarPortales/PracticaBigDataArquitect/blob/master/Ejemplos_Scrapy_y_uso_de_API's_C%C3%A9sar_Portales_Alonso.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF10oReQhBf_",
        "colab_type": "text"
      },
      "source": [
        "# **Ejemplos scrapy y uso de API's**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgkqZ7GnrmOQ",
        "colab_type": "text"
      },
      "source": [
        "# **Uso de Google API**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leT2E1YormWk",
        "colab_type": "text"
      },
      "source": [
        "Usaremos Google Api para encontrar las direcciones que se corresponden con las localizaciones y para cálculos de distancias con diversos puntos (en el ejemplo con el Museo del Prado).\n",
        "\n",
        "En teoría habría que hacer una función que pasase las coordenadas como parámetro, no lo he hecho por el coste que supondría. \n",
        "\n",
        "Simplemente pongo un ejemplo de como  acceder a la información "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLjw9fro56TV",
        "colab_type": "code",
        "outputId": "16eaf06b-9b33-45e2-e437-d6e807a375fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "pip install requests"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (2.21.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests) (2019.6.16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s56lON1rnR1",
        "colab_type": "code",
        "outputId": "97134ce8-5c7a-4b64-fb1e-4ae18c13045d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "import json, requests\n",
        "\n",
        "\n",
        "url='https://maps.googleapis.com/maps/api/distancematrix/json?units=metric&origins=40.4069528,-3.6708945&destinations=40.4101197,-3.6858859&mode=walking&key=AIzaSyCJ6JxlZGrXzA64nVv-3eYC5rMR7oasgQY'\n",
        "\n",
        "resp = requests.get(url=url)\n",
        "print (resp)\n",
        "data = json.loads(resp.text)\n",
        "print(data)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Response [200]>\n",
            "{'destination_addresses': ['Paseo Fernán Núñez, 6, 28009 Madrid, Spain'], 'origin_addresses': ['Av.mediterraneo-pza.conde Casal, 28009 Madrid, Spain'], 'rows': [{'elements': [{'distance': {'text': '1.5 km', 'value': 1517}, 'duration': {'text': '21 mins', 'value': 1244}, 'status': 'OK'}]}], 'status': 'OK'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8C4PXTThT9d",
        "colab_type": "text"
      },
      "source": [
        "# **Buscamos cual es la última cotización euro-dólar para añadir información del cambio**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvaNOBHihUJy",
        "colab_type": "text"
      },
      "source": [
        "**Instalamos beautifulsoup4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlcuNJR0hVQ7",
        "colab_type": "code",
        "outputId": "b0ffb7a8-4420-467e-c1bf-b9d1882753f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install beautifulsoup4"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (4.6.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDehrvuuh6rq",
        "colab_type": "text"
      },
      "source": [
        "**Instalamos requests**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2knuKAkMV_oI",
        "colab_type": "code",
        "outputId": "dc205a20-17a5-4ec9-8579-7cfbbea59aae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "pip install requests"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (2.21.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests) (2019.6.16)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6HDaeJLiFZz",
        "colab_type": "text"
      },
      "source": [
        "**Código que obtendría la última cotización de 'Expansión'**\n",
        "\n",
        "Creamos la función cotizacionDolar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mxrc-Co-cWfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def cotizacionDolar():\n",
        "    # indicar la ruta\n",
        "    url_page='https://www.expansion.com/mercados/cotizaciones/valores/eurodolar_DVEUDU.html'\n",
        "\n",
        "    #hacemos el get a la url\n",
        "    req = requests.get(url_page)\n",
        "    status_code = req.status_code\n",
        "\n",
        "    if status_code == 200:\n",
        "\n",
        "        # Pasamos el contenido HTML de la web a un objeto BeautifulSoup()\n",
        "        html = BeautifulSoup(req.text, \"html.parser\")\n",
        "\n",
        "        # Obtenemos todos los divs donde están las entradas\n",
        "        entradas = html.find_all('div', {'id': 'ultimos_datos'})\n",
        "\n",
        "        # Recorremos todas las entradas para extraer el valor\n",
        "        for i, entrada in enumerate(entradas):\n",
        "\n",
        "            # Con el método \"getText()\" no nos devuelve el HTML\n",
        "            titulo = entrada.find('li', {'class': 'cotizacion'}).getText()\n",
        "\n",
        "\n",
        "            # Imprimo el valor de la cotización\n",
        "            return (titulo)\n",
        "    else:\n",
        "        return(0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1ePdaei7PQv",
        "colab_type": "text"
      },
      "source": [
        "**Comprobamos que la función devuelve el resultado debido**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqN4T72w7PjT",
        "colab_type": "code",
        "outputId": "41d73303-070c-4ab7-86df-ae8fe0aa086a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "valordolar=cotizacionDolar()\n",
        "print(valordolar)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1,11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvVj2SmwjJXL",
        "colab_type": "text"
      },
      "source": [
        "**--------------------------------------------------------------------------**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOW08NTnjJlh",
        "colab_type": "text"
      },
      "source": [
        "# **Hacemos scrapy para descargar en un csv datos de actividades que realizar en Madrid**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMFaJ9IijJ8C",
        "colab_type": "text"
      },
      "source": [
        "**Montamos nuestra unidad de drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jDjZOY_TGtS",
        "colab_type": "code",
        "outputId": "0ea3c974-12b5-4334-bf10-8c88c119b1c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eQgmEdcla3I",
        "colab_type": "text"
      },
      "source": [
        "**Generamos ActividadesMadrid.csv en la carpeta BigDataArq/Input**\n",
        "(habría que generar un archivo por cada una de las ciudades con las que se desee trabajar.\n",
        "Simplemente, habrá que cambiar la URL y el nombre del archivo)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeUEwwEiWlEw",
        "colab_type": "code",
        "outputId": "706d7d66-be82-4171-9408-d44aaecb356e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "# indicar la ruta\n",
        "url_page='https://www.minube.com/a/externalact/c/1252/activity_category'\n",
        "print(url_page)\n",
        "req = requests.get(url_page)\n",
        "status_code = req.status_code\n",
        " \n",
        "filep = open('/content/drive/My Drive/BigDataArq/Input/ActivMad.csv', 'w')\n",
        "if status_code == 200:\n",
        "\n",
        "  # Pasamos el contenido HTML de la web a un objeto BeautifulSoup()\n",
        "  html = BeautifulSoup(req.text, \"html.parser\")\n",
        "  \n",
        "  # Obtenemos todos los divs donde están las entradas\n",
        "  entradas = html.find_all('div', {'class': 'river detail '})\n",
        "  \n",
        " #Por sencillez del código, usaremos dos listas para guardar titulos y precio de las actividades\n",
        "  titulo=[]\n",
        "  precio=[]\n",
        "  \n",
        "  # Recorremos todas las entradas para extraer el título y el precio\n",
        "  for i, entrada in enumerate(entradas):\n",
        "      \n",
        "      visitas=entrada.find_all('a', {'class': 'titleItem'})\n",
        "     \n",
        "      importes=entrada.find_all('div', {'class': 'amount'})  \n",
        "      \n",
        "      \n",
        "      for j, visita in enumerate(visitas):\n",
        "\n",
        "          # Con el método \"getText()\" no nos devuelve el HTML\n",
        "\n",
        "          titulo.append(visita.getText().replace('\\n', '').replace(',', ''))\n",
        "\n",
        "         \n",
        "      \n",
        "      for j,importe in enumerate(importes):\n",
        "        precio.append(importe.getText().replace(',', '.'))\n",
        "      \n",
        "  longitud=len(titulo) \n",
        "  \n",
        "  #Escribimos los rótulos del fichero\n",
        "  filep.write('Título actividad' + ',' + 'Precio' + '\\n')\n",
        "  \n",
        "  for  k in range(1,longitud):\n",
        "    tit=titulo[k]\n",
        "    prec=str(precio[k])\n",
        "                                 \n",
        "    filep.write(tit + ',' + prec + '\\n')\n",
        "\n",
        "else:\n",
        "    print(status_code) \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://www.minube.com/a/externalact/c/1252/activity_category\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIPrE28shXxr",
        "colab_type": "text"
      },
      "source": [
        "# **Descargar los resultados**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIJ3kT1Vhb20",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('/content/drive/My Drive/BigDataArq/Input/ActivMad.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ABCQ9T1jS5Q",
        "colab_type": "text"
      },
      "source": [
        "# **Enviar resultados a Google Cloud**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjF1-TlbjXNx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "44e74772-8768-4b7d-937e-c48bd50a021e"
      },
      "source": [
        "# Necesitas saber el id de tu proyecto en la consola cloud de google (esta arriba a la izquierda)\n",
        "project_id = 'BDArc'\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "# Ahora nos traemos lo necesario para cloud storage\n",
        "from googleapiclient.discovery import build\n",
        "gcs_service = build('storage', 'v1')\n",
        "\n",
        "#nombre del segmento\n",
        "bucket_name = 'dataproc-55d4cd8d-292e-4fdf-ab80-2d9b9262122f-europe-west1'\n",
        "\n",
        "#nombre del fichero\n",
        "file_name = 'ActivMad1.csv'\n",
        "\n",
        "# Ahora cogemos el fichero del resultado del scrapping y lo subimos al bucket\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "media = MediaFileUpload('/content/drive/My Drive/BigDataArq/Input/ActivMad.csv', \n",
        "                        mimetype='text/plain',\n",
        "                        resumable=True)\n",
        "\n",
        "request = gcs_service.objects().insert(bucket=bucket_name, \n",
        "                                       name=file_name,\n",
        "                                       media_body=media)\n",
        "\n",
        "response = None\n",
        "while response is None:\n",
        "  # _ is a placeholder for a progress object that we ignore.\n",
        "  # (Our file is small, so we skip reporting progress.)\n",
        "  _, response = request.next_chunk()\n",
        "\n",
        "print('Carga completa')\n",
        "#Una vez haya finalizado la carga, los datos aparecerán en el explorador de datos almacenados de la consola de Cloud del proyecto:en el enlace\n",
        "print('https://console.cloud.google.com/storage/browser?project=' + project_id)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carga completa\n",
            "https://console.cloud.google.com/storage/browser?project=BDArc\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}